{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd48c6b2-a501-412e-a746-20325ca0bd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from timm.models.layers import DropPath\n",
    "from torchsummary import summary\n",
    "from lion_pytorch import Lion\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa096960-d40f-479e-a744-0978aed1310f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read our data\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "sample_data = pd.read_csv('submission_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "704f1349-47b1-4455-8d27-2c7355a09c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "train_data = train_data.astype(np.float32)\n",
    "test_data.iloc[:, 1:] = test_data.iloc[:, 1:].astype(np.float32)\n",
    "train_data.iloc[:, 0] -= train_data.label.min()\n",
    "train_data.iloc[:, 1:] = train_data.iloc[:, 1:] / 255\n",
    "test_data.iloc[:, 1:] = test_data.iloc[:, 1:] / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f44ec34-e8ed-475b-aa92-2ca73e812de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min label: 0.0\n",
      "Max label: 35.0\n",
      "Min pixel: 0.0\n",
      "Max pixel: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Check min, max label and min, max pixel value\n",
    "print(f'Min label: {train_data.label.min()}')\n",
    "print(f'Max label: {train_data.label.max()}')\n",
    "print(f'Min pixel: {train_data.iloc[:, 1:].min().min()}')\n",
    "print(f'Max pixel: {train_data.iloc[:, 1:].max().max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b159332e-050f-4d41-8ce6-4ecf2fe15f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel_0</th>\n",
       "      <th>pixel_1</th>\n",
       "      <th>pixel_2</th>\n",
       "      <th>pixel_3</th>\n",
       "      <th>pixel_4</th>\n",
       "      <th>pixel_5</th>\n",
       "      <th>pixel_6</th>\n",
       "      <th>pixel_7</th>\n",
       "      <th>pixel_8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_2490</th>\n",
       "      <th>pixel_2491</th>\n",
       "      <th>pixel_2492</th>\n",
       "      <th>pixel_2493</th>\n",
       "      <th>pixel_2494</th>\n",
       "      <th>pixel_2495</th>\n",
       "      <th>pixel_2496</th>\n",
       "      <th>pixel_2497</th>\n",
       "      <th>pixel_2498</th>\n",
       "      <th>pixel_2499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80208</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80209</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80210</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80211</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80212</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80213 rows Ã— 2501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel_0  pixel_1  pixel_2  pixel_3  pixel_4  pixel_5  pixel_6  \\\n",
       "0        1.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1        1.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2        1.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3        1.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4        1.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "...      ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "80208    6.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "80209   19.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "80210   18.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "80211   27.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "80212   25.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "       pixel_7  pixel_8  ...  pixel_2490  pixel_2491  pixel_2492  pixel_2493  \\\n",
       "0          0.0      0.0  ...         0.0         0.0         0.0         0.0   \n",
       "1          0.0      0.0  ...         0.0         0.0         0.0         0.0   \n",
       "2          0.0      0.0  ...         0.0         0.0         0.0         0.0   \n",
       "3          0.0      0.0  ...         0.0         0.0         0.0         0.0   \n",
       "4          0.0      0.0  ...         0.0         0.0         0.0         0.0   \n",
       "...        ...      ...  ...         ...         ...         ...         ...   \n",
       "80208      0.0      0.0  ...         0.0         0.0         0.0         0.0   \n",
       "80209      0.0      0.0  ...         0.0         0.0         0.0         0.0   \n",
       "80210      0.0      0.0  ...         0.0         0.0         0.0         0.0   \n",
       "80211      0.0      0.0  ...         0.0         0.0         0.0         0.0   \n",
       "80212      0.0      0.0  ...         0.0         0.0         0.0         0.0   \n",
       "\n",
       "       pixel_2494  pixel_2495  pixel_2496  pixel_2497  pixel_2498  pixel_2499  \n",
       "0             0.0         0.0         0.0         0.0         0.0         0.0  \n",
       "1             0.0         0.0         0.0         0.0         0.0         0.0  \n",
       "2             0.0         0.0         0.0         0.0         0.0         0.0  \n",
       "3             0.0         0.0         0.0         0.0         0.0         0.0  \n",
       "4             0.0         0.0         0.0         0.0         0.0         0.0  \n",
       "...           ...         ...         ...         ...         ...         ...  \n",
       "80208         0.0         0.0         0.0         0.0         0.0         0.0  \n",
       "80209         0.0         0.0         0.0         0.0         0.0         0.0  \n",
       "80210         0.0         0.0         0.0         0.0         0.0         0.0  \n",
       "80211         0.0         0.0         0.0         0.0         0.0         0.0  \n",
       "80212         0.0         0.0         0.0         0.0         0.0         0.0  \n",
       "\n",
       "[80213 rows x 2501 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check our perfect data)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cd4ace5-f67a-445f-ad2a-6f1c3b3c0990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some augmentation\n",
    "img_tform_1 = transforms.Compose([\n",
    "    transforms.ToPILImage(),transforms.ToTensor(),transforms.Normalize(mean=(0.0253), std=(0.1131))])\n",
    "\n",
    "img_tform_2 = transforms.Compose([\n",
    "    transforms.ToPILImage(),transforms.RandomRotation(15),transforms.ToTensor(),transforms.Normalize(mean=(0.0253), std=(0.1131))])\n",
    "\n",
    "img_tform_3 = transforms.Compose([\n",
    "    transforms.ToPILImage(),transforms.RandomRotation(45),transforms.ToTensor(),transforms.Normalize(mean=(0.0253), std=(0.1131))])\n",
    "\n",
    "img_tform_4 = transforms.Compose([\n",
    "    transforms.ToPILImage(),transforms.RandomAffine(degrees=20, translate=(0.15,0.15), scale=(0.85,0.85)),\\\n",
    "    transforms.ToTensor(),transforms.Normalize(mean=(0.0253), std=(0.1131))])\n",
    "\n",
    "img_tform_5 = transforms.Compose([\n",
    "    transforms.ToPILImage(),transforms.RandomAffine(degrees=15, translate=(0.25,0.25)),\\\n",
    "    transforms.ToTensor(),transforms.Normalize(mean=(0.0253), std=(0.1131))])\n",
    "\n",
    "img_tform_6 = transforms.Compose([\n",
    "    transforms.ToPILImage(),transforms.RandomAffine(degrees=5, translate=(0.5,0.5)),\\\n",
    "    transforms.ToTensor(),transforms.Normalize(mean=(0.0253), std=(0.1131))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "404e0611-a5a1-47ec-899a-7666c5e5709f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset classes\n",
    "class KyrMnistDataset(Dataset):\n",
    "    def __init__(self, features, transform = img_tform_1): \n",
    "        self.features = features.iloc[:,1:].values.reshape((-1,50,50)).astype(np.float32)\n",
    "        self.targets = torch.from_numpy(features.label.values)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.transform(self.features[idx]), self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc60afd0-93d7-446b-bc99-19896ffaf8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set hyperparameters\n",
    "learning_rate = 3e-4\n",
    "batch_size = 64\n",
    "seed = 42\n",
    "num_epochs = 15\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7f6c229-4bc7-47fa-ab6c-29ac1562d84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "def create_dataloaders(seed=seed, validation_size=0.1, df=train_data, batch_size=batch_size):\n",
    "\n",
    "    train_df, val_df = train_test_split(df, test_size=validation_size, random_state=seed, stratify=df['label'])\n",
    "\n",
    "    train_data_1 = KyrMnistDataset(train_df)\n",
    "    train_data_2 = KyrMnistDataset(train_df, img_tform_2)\n",
    "    train_data_3 = KyrMnistDataset(train_df, img_tform_3)\n",
    "    train_data_4 = KyrMnistDataset(train_df, img_tform_4)\n",
    "    train_data_5 = KyrMnistDataset(train_df, img_tform_5)\n",
    "    train_data_6 = KyrMnistDataset(train_df, img_tform_6)\n",
    "    train_final = ConcatDataset([train_data_1, train_data_2, train_data_3, \n",
    "                                 train_data_4, train_data_5, train_data_6])\n",
    "\n",
    "    val_data = KyrMnistDataset(val_df)\n",
    "    \n",
    "    train_loader = DataLoader(train_final, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    valid_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49f5a7f1-6c43-426d-8ff9-409beb4f974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"\"\" LayerNorm that supports two data formats: channels_last (default) or channels_first. \n",
    "    The ordering of the dimensions in the inputs. channels_last corresponds to inputs with \n",
    "    shape (batch_size, height, width, channels) while channels_first corresponds to inputs \n",
    "    with shape (batch_size, channels, height, width).\n",
    "    \"\"\"\n",
    "    def __init__(self, normalized_shape, eps=1e-6, data_format='channels_first'):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(normalized_shape))\n",
    "        self.bias = nn.Parameter(torch.zeros(normalized_shape))\n",
    "        self.eps = eps\n",
    "        self.data_format = data_format\n",
    "        self.normalized_shape = (normalized_shape, )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.data_format == 'channels_last':\n",
    "            return F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n",
    "        elif self.data_format == 'channels_first':\n",
    "            u = x.mean(1, keepdim=True)\n",
    "            s = (x - u).pow(2).mean(1, keepdim=True)\n",
    "            x = (x - u) / torch.sqrt(s + self.eps)\n",
    "            x = self.weight[:, None, None] * x + self.bias[:, None, None]\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab541d34-bc4d-4ec0-8896-3d25cb1e76a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(dim, dim, kernel_size = 5, padding = 2, groups=dim)\n",
    "        self.pwconv1 = nn.Linear(dim, 4 * dim)\n",
    "        self.pwconv2 = nn.Linear(4 * dim, dim)\n",
    "        self.norm = LayerNorm(dim, data_format='channels_last')\n",
    "        self.act = nn.GELU()\n",
    "        self.drop_path = DropPath(0.2)\n",
    "        self.gamma = nn.Parameter(1e-6 * torch.ones((dim)), \n",
    "                                    requires_grad=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        x = self.conv1(x)\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = self.norm(x)\n",
    "        x = self.pwconv1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pwconv2(x)\n",
    "        x = self.gamma * x \n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = res + self.drop_path(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1369cdaf-64a4-4b9c-8ac6-913fefff208f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "class AmanNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3),\n",
    "            \n",
    "            LayerNorm(64),\n",
    "            nn.Conv2d(64, 64, kernel_size=2, stride=2),\n",
    "            \n",
    "            BasicBlock(64),\n",
    "            BasicBlock(64),\n",
    "            BasicBlock(64),\n",
    "            \n",
    "            LayerNorm(64),\n",
    "            nn.Conv2d(64, 128, kernel_size=2, stride=2),\n",
    "            \n",
    "            BasicBlock(128),\n",
    "            BasicBlock(128),\n",
    "            BasicBlock(128),\n",
    "            BasicBlock(128),\n",
    "            BasicBlock(128),\n",
    "            BasicBlock(128),\n",
    "            BasicBlock(128),\n",
    "            BasicBlock(128),\n",
    "            BasicBlock(128),\n",
    "            \n",
    "            LayerNorm(128),\n",
    "            nn.Conv2d(128, 256, kernel_size=2, stride=2),\n",
    "            \n",
    "            BasicBlock(256)\n",
    "        )\n",
    "        \n",
    "        self.avgpool = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 36)\n",
    "        )\n",
    "        \n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "            nn.init.trunc_normal_(m.weight, std=2e-2)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = AmanNet()\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e82d3fc-02e4-43c8-bd9e-e440c837cd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 48, 48]             640\n",
      "         LayerNorm-2           [-1, 64, 48, 48]             128\n",
      "            Conv2d-3           [-1, 64, 24, 24]          16,448\n",
      "            Conv2d-4           [-1, 64, 24, 24]           1,664\n",
      "         LayerNorm-5           [-1, 24, 24, 64]             128\n",
      "            Linear-6          [-1, 24, 24, 256]          16,640\n",
      "              GELU-7          [-1, 24, 24, 256]               0\n",
      "            Linear-8           [-1, 24, 24, 64]          16,448\n",
      "          DropPath-9           [-1, 64, 24, 24]               0\n",
      "       BasicBlock-10           [-1, 64, 24, 24]               0\n",
      "           Conv2d-11           [-1, 64, 24, 24]           1,664\n",
      "        LayerNorm-12           [-1, 24, 24, 64]             128\n",
      "           Linear-13          [-1, 24, 24, 256]          16,640\n",
      "             GELU-14          [-1, 24, 24, 256]               0\n",
      "           Linear-15           [-1, 24, 24, 64]          16,448\n",
      "         DropPath-16           [-1, 64, 24, 24]               0\n",
      "       BasicBlock-17           [-1, 64, 24, 24]               0\n",
      "           Conv2d-18           [-1, 64, 24, 24]           1,664\n",
      "        LayerNorm-19           [-1, 24, 24, 64]             128\n",
      "           Linear-20          [-1, 24, 24, 256]          16,640\n",
      "             GELU-21          [-1, 24, 24, 256]               0\n",
      "           Linear-22           [-1, 24, 24, 64]          16,448\n",
      "         DropPath-23           [-1, 64, 24, 24]               0\n",
      "       BasicBlock-24           [-1, 64, 24, 24]               0\n",
      "        LayerNorm-25           [-1, 64, 24, 24]             128\n",
      "           Conv2d-26          [-1, 128, 12, 12]          32,896\n",
      "           Conv2d-27          [-1, 128, 12, 12]           3,328\n",
      "        LayerNorm-28          [-1, 12, 12, 128]             256\n",
      "           Linear-29          [-1, 12, 12, 512]          66,048\n",
      "             GELU-30          [-1, 12, 12, 512]               0\n",
      "           Linear-31          [-1, 12, 12, 128]          65,664\n",
      "         DropPath-32          [-1, 128, 12, 12]               0\n",
      "       BasicBlock-33          [-1, 128, 12, 12]               0\n",
      "           Conv2d-34          [-1, 128, 12, 12]           3,328\n",
      "        LayerNorm-35          [-1, 12, 12, 128]             256\n",
      "           Linear-36          [-1, 12, 12, 512]          66,048\n",
      "             GELU-37          [-1, 12, 12, 512]               0\n",
      "           Linear-38          [-1, 12, 12, 128]          65,664\n",
      "         DropPath-39          [-1, 128, 12, 12]               0\n",
      "       BasicBlock-40          [-1, 128, 12, 12]               0\n",
      "           Conv2d-41          [-1, 128, 12, 12]           3,328\n",
      "        LayerNorm-42          [-1, 12, 12, 128]             256\n",
      "           Linear-43          [-1, 12, 12, 512]          66,048\n",
      "             GELU-44          [-1, 12, 12, 512]               0\n",
      "           Linear-45          [-1, 12, 12, 128]          65,664\n",
      "         DropPath-46          [-1, 128, 12, 12]               0\n",
      "       BasicBlock-47          [-1, 128, 12, 12]               0\n",
      "           Conv2d-48          [-1, 128, 12, 12]           3,328\n",
      "        LayerNorm-49          [-1, 12, 12, 128]             256\n",
      "           Linear-50          [-1, 12, 12, 512]          66,048\n",
      "             GELU-51          [-1, 12, 12, 512]               0\n",
      "           Linear-52          [-1, 12, 12, 128]          65,664\n",
      "         DropPath-53          [-1, 128, 12, 12]               0\n",
      "       BasicBlock-54          [-1, 128, 12, 12]               0\n",
      "           Conv2d-55          [-1, 128, 12, 12]           3,328\n",
      "        LayerNorm-56          [-1, 12, 12, 128]             256\n",
      "           Linear-57          [-1, 12, 12, 512]          66,048\n",
      "             GELU-58          [-1, 12, 12, 512]               0\n",
      "           Linear-59          [-1, 12, 12, 128]          65,664\n",
      "         DropPath-60          [-1, 128, 12, 12]               0\n",
      "       BasicBlock-61          [-1, 128, 12, 12]               0\n",
      "           Conv2d-62          [-1, 128, 12, 12]           3,328\n",
      "        LayerNorm-63          [-1, 12, 12, 128]             256\n",
      "           Linear-64          [-1, 12, 12, 512]          66,048\n",
      "             GELU-65          [-1, 12, 12, 512]               0\n",
      "           Linear-66          [-1, 12, 12, 128]          65,664\n",
      "         DropPath-67          [-1, 128, 12, 12]               0\n",
      "       BasicBlock-68          [-1, 128, 12, 12]               0\n",
      "           Conv2d-69          [-1, 128, 12, 12]           3,328\n",
      "        LayerNorm-70          [-1, 12, 12, 128]             256\n",
      "           Linear-71          [-1, 12, 12, 512]          66,048\n",
      "             GELU-72          [-1, 12, 12, 512]               0\n",
      "           Linear-73          [-1, 12, 12, 128]          65,664\n",
      "         DropPath-74          [-1, 128, 12, 12]               0\n",
      "       BasicBlock-75          [-1, 128, 12, 12]               0\n",
      "           Conv2d-76          [-1, 128, 12, 12]           3,328\n",
      "        LayerNorm-77          [-1, 12, 12, 128]             256\n",
      "           Linear-78          [-1, 12, 12, 512]          66,048\n",
      "             GELU-79          [-1, 12, 12, 512]               0\n",
      "           Linear-80          [-1, 12, 12, 128]          65,664\n",
      "         DropPath-81          [-1, 128, 12, 12]               0\n",
      "       BasicBlock-82          [-1, 128, 12, 12]               0\n",
      "           Conv2d-83          [-1, 128, 12, 12]           3,328\n",
      "        LayerNorm-84          [-1, 12, 12, 128]             256\n",
      "           Linear-85          [-1, 12, 12, 512]          66,048\n",
      "             GELU-86          [-1, 12, 12, 512]               0\n",
      "           Linear-87          [-1, 12, 12, 128]          65,664\n",
      "         DropPath-88          [-1, 128, 12, 12]               0\n",
      "       BasicBlock-89          [-1, 128, 12, 12]               0\n",
      "        LayerNorm-90          [-1, 128, 12, 12]             256\n",
      "           Conv2d-91            [-1, 256, 6, 6]         131,328\n",
      "           Conv2d-92            [-1, 256, 6, 6]           6,656\n",
      "        LayerNorm-93            [-1, 6, 6, 256]             512\n",
      "           Linear-94           [-1, 6, 6, 1024]         263,168\n",
      "             GELU-95           [-1, 6, 6, 1024]               0\n",
      "           Linear-96            [-1, 6, 6, 256]         262,400\n",
      "         DropPath-97            [-1, 256, 6, 6]               0\n",
      "       BasicBlock-98            [-1, 256, 6, 6]               0\n",
      "AdaptiveAvgPool2d-99            [-1, 256, 1, 1]               0\n",
      "         Flatten-100                  [-1, 256]               0\n",
      "         Dropout-101                  [-1, 256]               0\n",
      "          Linear-102                   [-1, 36]           9,252\n",
      "================================================================\n",
      "Total params: 2,046,116\n",
      "Trainable params: 2,046,116\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 31.51\n",
      "Params size (MB): 7.81\n",
      "Estimated Total Size (MB): 39.32\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Check model info\n",
    "print(summary(model, (1, 50, 50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68a93a5b-e1ca-42f9-b0a9-a2b67497ea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and validation function \n",
    "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device, epoch):\n",
    "    model.train() \n",
    "    final_loss = 0  \n",
    "    train_acc = 0\n",
    "    total = 0\n",
    "    loop = tqdm(enumerate(dataloader), total=len(dataloader), leave=False, ncols=120)\n",
    "    loop.set_description(f'Epoch: [{epoch+1}/{num_epochs}]')\n",
    "    for batch_idx, (features, labels) in loop:\n",
    "        inputs, targets = features.to(device, non_blocking=True), labels.to(device, non_blocking=True).long() \n",
    "        \n",
    "        outputs = model(inputs) \n",
    "        loss = loss_fn(outputs, targets) \n",
    "        \n",
    "        for param in model.parameters():\n",
    "            param.grad = None\n",
    "        model.zero_grad(set_to_none=True)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        scheduler.step() \n",
    "        \n",
    "        total += len(targets)\n",
    "        final_loss += loss.item() \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        train_acc += ((predicted == targets).sum().item())\n",
    "        if batch_idx % 200 == 0:\n",
    "            loop.update()\n",
    "            loop.set_postfix(loss=f'{final_loss/(batch_idx+1):.5f}', acc=f'{train_acc/total:.5f}')\n",
    "        \n",
    "    final_loss /= len(dataloader) \n",
    "    train_acc = (train_acc / total) * 100\n",
    "    \n",
    "    return final_loss, train_acc\n",
    "\n",
    "\n",
    "def valid_fn(model, loss_fn, dataloader, device, epoch, best_result):\n",
    "    model.eval() \n",
    "    final_loss = 0\n",
    "    valid_preds = []\n",
    "    val_acc=0\n",
    "    total=0\n",
    "    loop = tqdm(enumerate(dataloader), total=len(dataloader), leave=False)\n",
    "    for batch_idx, (features, labels) in loop:\n",
    "        inputs, targets = features.to(device, non_blocking=True), labels.to(device, non_blocking=True).long()\n",
    "        outputs = model(inputs) \n",
    "        loss = loss_fn(outputs, targets) \n",
    "        total += len(targets)\n",
    "        final_loss += loss.item() \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        val_acc += ((predicted == targets).sum().item())\n",
    "        loop.set_description(f'Epoch: [{epoch+1}/{num_epochs}]')\n",
    "        loop.set_postfix(loss=final_loss/(batch_idx+1), acc=val_acc/total)\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    val_acc = (val_acc / total) * 100\n",
    "    \n",
    "    if val_acc > best_result:\n",
    "        name = 'best_models/model_v' + str(epoch+1) + '.pth'\n",
    "        torch.save(model.state_dict(), name)\n",
    "        best_result = val_acc\n",
    "    \n",
    "    return final_loss, val_acc, best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "307fd1ff-c5ce-4f37-82ed-085eed6ff899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1653, 1.1611, 1.1685, 1.1658, 1.1637, 1.1564, 1.1798, 1.1798, 1.1538,\n",
       "        1.1616, 1.1334, 1.1648, 1.1137, 1.1611, 1.1590, 1.0051, 1.1669, 1.0000,\n",
       "        1.1749, 1.1680, 1.1722, 1.1658, 1.3991, 1.0020, 1.1658, 1.1669, 1.1765,\n",
       "        1.1225, 1.1685, 1.1674, 1.1653, 1.1658, 1.1653, 1.1658, 1.1690, 1.1374],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating weights for each class, because our dataset is imbalanced\n",
    "weights = train_data.copy()\n",
    "weights['count_of_targets'] = weights['label'].map(weights['label'].value_counts())\n",
    "weights.sort_values('label', inplace=True)\n",
    "weights.drop_duplicates('label', inplace=True)\n",
    "n_samples = list(weights['count_of_targets'])\n",
    "weights = [(max(n_samples)/n) for n in n_samples]\n",
    "loss_weights = torch.FloatTensor(weights).to(device)\n",
    "loss_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa6ade32-4a0e-414a-ad33-d5d220f30b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training function\n",
    "def run_training(seed, train_acc_lst, train_loss_lst, val_acc_lst, val_loss_lst):\n",
    "    # train and data val dataloaders\n",
    "    train_loader, valid_loader = create_dataloaders(seed=seed)\n",
    "    best_result = 0\n",
    "    \n",
    "    optimizer = Lion(model.parameters(), lr=learning_rate, weight_decay=3e-4)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max = num_epochs, eta_min = 3e-4)\n",
    "    loss_fn = nn.CrossEntropyLoss(weight=loss_weights)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train_fn(model, optimizer,scheduler, loss_fn, train_loader, device, epoch) #training loss and accuracy\n",
    "        train_acc_lst.append(train_acc)\n",
    "        train_loss_lst.append(train_loss)\n",
    "        \n",
    "        val_loss, val_acc, best_result = valid_fn(model, loss_fn, valid_loader, device, epoch, best_result) #validation loss and accuracy\n",
    "        val_acc_lst.append(val_acc)\n",
    "        val_loss_lst.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1eb8c69f-cd31-407d-a63e-29d6c52e7981",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    }
   ],
   "source": [
    "train_acc_lst = []\n",
    "train_loss_lst = []\n",
    "val_acc_lst = []\n",
    "val_loss_lst = []\n",
    "run_training(seed, train_acc_lst, train_loss_lst, val_acc_lst, val_loss_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2a4487-d4d6-4b57-81c0-13fdf0a26342",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
